
\newpage

\item A confusion matrix is a table that is often used to describe the performance of a binary classification procedure on a set of test data for which the true values are known.
\begin{center}
\begin{tabular}{|c|c|c|}
\hline  & Predicted Negative & Predicted Positive \\ 
\hline Observed Negative & True Negative & False Positive \\ 
\hline Observed Positive & False Negative & True Positive \\ 
\hline 
\end{tabular} 
\end{center}
\begin{enumerate}[(i)]



\item Define each of the following appraisal metrics for binary classification:
\begin{enumerate}[(i)]
\item  Accuracy,
\item  Precision,
\item  Recall.
\end{enumerate}

\item (2 Marks) What is the F-measure? Explain its function and how it is computed.\\ 
\noindent \textit{ Hint: F-score = $(2 \times P \times R) / (P + R)$.}
%\item[iii.](2 Marks) Define Specificity and Sensitivity. You make reference to previous answers.
%\item[iv.](3 Marks) What is a ROC curve? Explain its function, how it is determined, and the means of interpreting the curve. Support your answer with a sketch.
\end{enumerate}


% \item %  Binary Classification (4 Marks)
% For the confusion matrix below, calculate the following appraisal metrics.
%
%\begin{enumerate}[(i)]
%\item  Accuracy,
%\item  Recall,
%\item  Precision,
%\item  F-score.
%\end{enumerate}
%
%
% \begin{center}
%
%\begin{tabular}{|c||c|c|}
%\hline 
%& Predict Negative & Predict Positive \\ \hline  \hline 
%Observed Negative & 9300 &  100 \\ \hline 
%Observed Positive & 200 & 400 \\ \hline 
% \end{tabular} 
% \end{center}

\medskip


\end{enumerate}
\end{document}